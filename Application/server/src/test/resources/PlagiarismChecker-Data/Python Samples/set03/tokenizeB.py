from nltk.tokenize import word_tokenize

tokens = word_tokenize(sample)
tokens